

import sys
import time
import csv
import random
import threading
import os
import sqlite3
from da import *  # DistAlgo primitives

# Provide a timeout helper when DA runtime does not supply one in run loop
def timeout(t: float):
	time.sleep(t)
	return True

# === Configuration ===
TIMEOUT = 3.0            # Base client/driver timeout (allows more 2PC retries under churn)
TWO_PC_TIMEOUT = 2.8     # Internal 2PC wait (must be < client TIMEOUT)
HEARTBEAT_INTERVAL = 0.4
HEARTBEAT_TIMEOUT = 1.0
ELECTION_TIMEOUT = 1.5   # Faster failover to fit client timeout
PREPARE_BACKOFF = 0.5
PREPARE_RETRY_INTERVAL = 0.25
MAX_CANDIDATE_TIME = 2 * ELECTION_TIMEOUT
ELECTION_JITTER = 0.4

VERBOSE_LOG = False
INITIAL_BALANCE = 10


# === Logging Helpers ===
def _emit(msg:str):
	try:
		output(msg)
	except Exception:
		print(msg)


def log_debug(msg:str):
	if VERBOSE_LOG:
		_emit(msg)


def log_info(msg:str):
	_emit(msg)


# === Helpers ===
def parse_transaction(tx_str):
	if not tx_str or tx_str.strip() == "":
		return None
	# Ignore failure/recovery markers that live in the tx column
	if tx_str.strip().startswith('F(') or tx_str.strip().startswith('R('):
		return None
	tx_str = tx_str.strip().strip('()')
	parts = [p.strip() for p in tx_str.split(',')]
	if len(parts) == 3:
		try:
			return (int(parts[0]), int(parts[1]), int(parts[2]))
		except Exception:
			return None
	if len(parts) == 1:
		try:
			return (int(parts[0]),)
		except Exception:
			return None
	return None


def parse_live_nodes(nodes_str):
	if not nodes_str or nodes_str.strip() == "":
		return []
	nodes_str = nodes_str.strip().strip('[]')
	return [n.strip() for n in nodes_str.split(',') if n.strip()]


def shard_for(key:int):
	if key <= 3000:
		return 1
	if key <= 6000:
		return 2
	return 3


def shard_bounds(shard_id:int):
	if shard_id == 1:
		return (1, 3000)
	if shard_id == 2:
		return (3001, 6000)
	return (6001, 9000)


class PersistentStore:
	"""SQLite-backed key/balance store with a dict-like surface."""

	def __init__(self, node_name:str, shard_id:int, base_dir:str = "data"):
		self.node_name = node_name
		self.shard_id = shard_id
		self.base_dir = base_dir
		os.makedirs(base_dir, exist_ok=True)
		self.path = os.path.join(base_dir, f"{node_name}_shard{shard_id}.sqlite")
		self.conn = sqlite3.connect(self.path, check_same_thread=False)
		self.conn.execute("PRAGMA journal_mode=WAL")
		self.conn.execute("CREATE TABLE IF NOT EXISTS accounts (key INTEGER PRIMARY KEY, balance INTEGER)")
		self.conn.commit()
		self._preload_if_empty()

	def _preload_if_empty(self):
		cur = self.conn.execute("SELECT COUNT(*) FROM accounts")
		row = cur.fetchone()
		if not row or row[0] == 0:
			start, end = shard_bounds(self.shard_id)
			rows = [(k, INITIAL_BALANCE) for k in range(start, end + 1)]
			self.conn.executemany("INSERT INTO accounts(key, balance) VALUES (?, ?)", rows)
			self.conn.commit()

	def reset(self):
		start, end = shard_bounds(self.shard_id)
		self.conn.execute("DELETE FROM accounts")
		rows = [(k, INITIAL_BALANCE) for k in range(start, end + 1)]
		self.conn.executemany("INSERT INTO accounts(key, balance) VALUES (?, ?)", rows)
		self.conn.commit()

	def _upsert_default(self, key:int, value:int):
		self.conn.execute("INSERT OR REPLACE INTO accounts(key, balance) VALUES (?, ?)", (key, value))
		self.conn.commit()
		return value

	def get(self, key:int, default=None):
		cur = self.conn.execute("SELECT balance FROM accounts WHERE key=?", (key,))
		row = cur.fetchone()
		if row is None:
			return default
		return row[0]

	def __getitem__(self, key:int):
		val = self.get(key, INITIAL_BALANCE)
		return self._upsert_default(key, val)

	def __setitem__(self, key:int, value:int):
		self._upsert_default(key, value)

	def __contains__(self, key:int):
		cur = self.conn.execute("SELECT 1 FROM accounts WHERE key=? LIMIT 1", (key,))
		return cur.fetchone() is not None

	def items(self):
		return [(row[0], row[1]) for row in self.conn.execute("SELECT key, balance FROM accounts")]

	def keys(self):
		return [row[0] for row in self.conn.execute("SELECT key FROM accounts")]

	def values(self):
		return [row[0] for row in self.conn.execute("SELECT balance FROM accounts")]


# === Parsing ===
def read_tests(csv_file):
	test_sets = []
	current = None
	with open(csv_file, 'r') as f:
		reader = csv.reader(f)
		next(reader, None)
		for row in reader:
			if not row or len(row) < 2:
				continue
			set_num = row[0].strip()
			tx_str = row[1].strip()
			live_nodes_str = row[2].strip() if len(row) > 2 else ''

			if set_num:
				if current:
					test_sets.append(current)
				current = {'id': set_num, 'transactions': [], 'live_nodes': parse_live_nodes(live_nodes_str)}

			if not current:
				continue

			if tx_str:
				if tx_str.startswith('F(') and tx_str.endswith(')'):
					current['transactions'].append(('FAIL', tx_str[2:-1]))
				elif tx_str.startswith('R(') and tx_str.endswith(')'):
					current['transactions'].append(('RECOVER', tx_str[2:-1]))
				else:
					tx = parse_transaction(tx_str)
					if tx:
						current['transactions'].append(('TX', tx))

		if current:
			test_sets.append(current)
	return test_sets


# === Driver ===

class Driver(process):
	def setup(csv_path:str, node_map:dict, clusters:dict, cluster_leaders:dict):
		self.test_sets = read_tests(csv_path)
		self.node_map = node_map
		self.clusters = clusters
		self.cluster_leaders = cluster_leaders
		self.proc_to_name = {proc: name for name, proc in node_map.items()}
		self.cluster_name_map = {cid: {self.proc_to_name.get(p, str(p)) for p in procs} for cid, procs in clusters.items()}
		self.pending = {}
		self.stats = {}
		self.all_nodes = set(node_map.values())

	def run():
		for set_info in self.test_sets:
			set_id = set_info['id']
			txs = set_info['transactions']
			live_nodes = set(set_info['live_nodes']) if set_info['live_nodes'] else set(self.node_map.keys())

			# Flush state
			send(('RESET',), to=list(self.all_nodes))
			time.sleep(TIMEOUT * 0.2)

			# Apply live set
			for name, proc in self.node_map.items():
				if name in live_nodes:
					send(('RECOVER',), to=proc)
				else:
					send(('FAIL',), to=proc)

			time.sleep(TIMEOUT * 0.2)

			# Run transactions sequentially
			total = 0
			lat_sum = 0.0
			set_start = time.time()

			for idx, (kind, payload) in enumerate(txs, start=1):
				if kind == 'FAIL':
					if payload in self.node_map:
						send(('FAIL',), to=self.node_map[payload])
						live_nodes.discard(payload)
					continue
				if kind == 'RECOVER':
					if payload in self.node_map:
						send(('RECOVER',), to=self.node_map[payload])
						live_nodes.add(payload)
					continue
				if kind != 'TX':
					continue

				tx = payload
				txid = (int(set_id), idx)

				# Pick cluster leader target
				shard = shard_for(tx[0]) if len(tx) >= 1 else 1
				leader_proc = self.cluster_leaders.get(shard)
				leader_name = self.proc_to_name.get(leader_proc)
				leader_target = None
				if leader_name and leader_name in live_nodes:
					leader_target = leader_proc
				else:
					shard_procs = self.clusters.get(shard, set())
					live_candidates = [p for p in shard_procs if self.proc_to_name.get(p) in live_nodes]
					if live_candidates:
						leader_target = live_candidates[0]
				if not leader_target:
					leader_target = leader_proc
				if not leader_target:
					log_info(f"No leader target for shard {shard}, skipping {tx}")
					continue

				start_ts = time.time()
				send(('CLIENT_TX', tx, txid, self), to=leader_target)

				res = None
				deadline = start_ts + TIMEOUT
				while time.time() < deadline:
					if txid in self.pending:
						res = self.pending.pop(txid)
						break
					await(timeout(0.05))
				if res is None and txid in self.pending:
					res = self.pending.pop(txid)
				if res is not None:
					lat_sum += (time.time() - start_ts)
					total += 1
					log_info(f"Set {set_id} tx {tx} -> {res}")
				else:
					log_info(f"Set {set_id} tx {tx} timed out")

			elapsed = max(time.time() - set_start, 1e-6)
			throughput = total / elapsed
			avg_lat = (lat_sum / total) if total else 0.0
			log_info(f"Set {set_id} throughput={throughput:.2f} tx/s avg_lat={avg_lat:.3f}s count={total}")
			self.stats[set_id] = {'throughput': throughput, 'avg_lat': avg_lat, 'count': total}

			send(('PRINT_DB', set_id), to=list(self.all_nodes))
			send(('PRINT_VIEW', set_id), to=list(self.all_nodes))
			time.sleep(TIMEOUT * 0.2)

		send(('STOP',), to=list(self.all_nodes))

	def receive(msg=('TX_RESULT', req_id, result)):
		self.pending[req_id] = result

	def receive(msg=('PRINT_PERF',)):
		for sid, stat in self.stats.items():
			output(f"Set {sid} throughput={stat['throughput']:.2f} avg_lat={stat['avg_lat']:.3f}s count={stat['count']}")


# === Node ===

class Node(process):
	def setup(node_name:str, cluster_id:int, peers:set, all_nodes:set, cluster_map:dict, initial_leader:bool, initial_leader_proc):
		self.node_name = node_name
		self.cluster_id = cluster_id
		self.peers = peers - {self}
		self.all_nodes = all_nodes
		self.cluster_map = {k: set(v) for k, v in cluster_map.items()}
		self.is_initial_leader = initial_leader
		self.initial_leader_proc = initial_leader_proc

		self.status = 'LEADER' if initial_leader else 'FOLLOWER'
		self.ballot_num = (1, node_name, self) if initial_leader else (0, node_name, self)
		self.leader = self if initial_leader else initial_leader_proc
		self.current_leader = self.leader
		self.accept_log = set()
		self.committed_log = {}
		self.accepted_votes = {}
		self.promises = {}
		self.next_seq = 1
		self.last_executed = 0

		self.last_leader_msg = time.time()
		self.buffered_prepare = None
		self.last_prepare_received_time = 0.0
		self.last_election_time = 0.0
		self.candidate_start_time = 0.0
		self.leader_grace_until = 0.0
		self.live_peers = set(self.peers)
		self.live_cluster_size = len(self.live_peers) + 1
		self.modified_keys = set()

		self.db = PersistentStore(node_name, cluster_id)
		self.client_replies = {}
		self.pending_requests = set()
		self.sent_replies = set()
		self.locks = {}
		self.tx_table = {}
		self.tx_meta = {}
		self.wal = {}
		self.decision_outbox = {}
		self.pending_2pc = {}
		self.tx_client = {}
		self.backlog_prepared = set()
		self.backlog_decisions = []
		self.backlog_prepares = []

		self.new_view_messages = []

		self.is_failed = False
		self.shutdown = False

	# === Run loop ===
	def run():
		while not self.shutdown:
			if self.is_failed:
				await(self.is_failed == False or self.shutdown)
				continue

			if self.status == 'LEADER':
				# Process any buffered client requests now that we lead.
				for txid, tx, client in list(self.pending_requests):
					handle_client_tx(tx, txid, client)
					self.pending_requests.discard((txid, tx, client))
				if self.live_peers:
					send(('HEARTBEAT', self.ballot_num, self), to=self.live_peers)
				await(timeout(HEARTBEAT_INTERVAL * 0.75))
				# Resend outstanding 2PC decisions if needed
				now = time.time()
				for txid, info in list(self.decision_outbox.items()):
					if now - info.get('last_sent', 0) >= PREPARE_RETRY_INTERVAL:
						desc = info.get('decision')
						targets = info.get('targets', set())
						if targets:
							send(('DECISION', txid, desc), to=targets)
						self.decision_outbox[txid]['last_sent'] = now
						client = info.get('client')
						if client:
							send(('TX_RESULT', txid, desc), to=client)
				# Drive any fully prepared-but-undecided 2PCs after leadership changes.
				drive_pending_decisions()
				for txid, meta in list(self.pending_2pc.items()):
					# Retry PREPARE_TX to participants still pending
					if meta.get('state') == 'WAIT_PREPARED':
						participants = meta.get('participants', set())
						ready = meta.get('participants_ready', set())
						for shard in participants:
							if shard in ready:
								continue
							last_sent = meta.get('last_prepare_sent', 0)
							if now - last_sent >= PREPARE_RETRY_INTERVAL:
								targets = self.cluster_map.get(shard, set())
								if targets:
									send(('PREPARE_TX', txid, self.tx_meta[txid]['tx'], self.cluster_id, meta.get('seq_p'), meta.get('seq_p')), to=targets)
									meta['last_prepare_sent'] = now
									self.pending_2pc[txid] = meta
					if now - meta.get('ts', now) > TWO_PC_TIMEOUT and txid in self.tx_meta:
						decision = 'ABORT'
						seq_c = self.tx_meta[txid].get('commit_seq') or self.tx_meta[txid].get('prepare_seq') or self.next_seq
						propose_with_seq(seq_c, ('2PC_DECISION', txid, decision, 'COORD'))
						for shard in self.tx_meta[txid].get('participants', ()): 
							targets = self.cluster_map.get(shard, set())
							if targets:
								send(('DECISION', txid, decision), to=targets)
								self.decision_outbox[txid] = {'decision': decision, 'targets': set(targets), 'last_sent': now, 'client': self.tx_meta[txid].get('client')}
						del self.pending_2pc[txid]
			elif self.status == 'FOLLOWER':
				old = self.last_leader_msg
				jitter = random.uniform(0, ELECTION_JITTER)
				to_wait = (ELECTION_TIMEOUT + jitter) - (time.time() - old)
				if to_wait < 0:
					to_wait = 0
				if await(self.last_leader_msg > old):
					pass
				elif timeout(to_wait):
					handle_timer_expiry()
				# Periodically replay backlog queues even as follower to avoid loss
				if self.backlog_prepares:
					pending_preps = list(self.backlog_prepares)
					self.backlog_prepares = []
					for txid, tx, coord_shard, seq_p, seq_c in pending_preps:
						send(('PREPARE_TX', txid, tx, coord_shard, seq_p, seq_c), to=self)
				if self.backlog_prepared:
					pending_prepared = list(self.backlog_prepared)
					self.backlog_prepared.clear()
					for txid in pending_prepared:
						send(('PREPARED', txid), to=self)
				if self.backlog_decisions:
					pending_dec = list(self.backlog_decisions)
					self.backlog_decisions = []
					for txid, decision in pending_dec:
						send(('DECISION', txid, decision), to=self)
			else:  # CANDIDATE
				if await(self.status != 'CANDIDATE' or self.shutdown):
					pass
				elif timeout(PREPARE_RETRY_INTERVAL):
					now = time.time()
					if self.candidate_start_time and (now - self.candidate_start_time) >= MAX_CANDIDATE_TIME:
						self.status = 'FOLLOWER'
						self.last_leader_msg = now
					elif self.live_peers:
						send(('PREPARE', self.ballot_num), to=self.live_peers)
						self.last_leader_msg = now

	# === Heartbeats & Election ===
	def drive_pending_decisions():
		for txid, meta in list(self.tx_meta.items()):
			if not meta or meta.get('decision'):
				continue
			if meta.get('prepared', {}).get('COORD') and meta.get('prepared', {}).get('PART'):
					decision = 'COMMIT'
					seq_c = meta.get('commit_seq') or meta.get('prepare_seq') or self.next_seq
					propose_with_seq(seq_c, ('2PC_DECISION', txid, decision, 'COORD'))
					client = meta.get('client')
					for shard in meta.get('participants', ()): 
						targets = self.cluster_map.get(shard, set())
						if targets:
							send(('DECISION', txid, decision), to=targets)
							self.decision_outbox[txid] = {'decision': decision, 'targets': set(targets), 'last_sent': time.time(), 'client': client}
					if client:
						send(('TX_RESULT', txid, decision), to=client)
	def handle_timer_expiry():
		if self.status != 'FOLLOWER' or self.is_failed:
			return
		if (time.time() - self.last_leader_msg) < HEARTBEAT_TIMEOUT:
			return
		now = time.time()
		if (now - self.last_prepare_received_time) < PREPARE_BACKOFF:
			return
		start_election()

	def should_i_lead():
		live_names = [getattr(p, 'node_name', str(p)) for p in self.live_peers] + [self.node_name]
		return self.node_name == min(live_names)

	def start_election():
		if self.is_failed or self.status == 'CANDIDATE' or self.status == 'LEADER':
			return
		if not should_i_lead():
			self.last_leader_msg = time.time()
			return
		self.status = 'CANDIDATE'
		self.ballot_num = (self.ballot_num[0] + 1, self.node_name, self)
		key = (self.ballot_num[0], self.ballot_num[1])
		self.promises[key] = {self: set(self.accept_log)}
		self.last_election_time = time.time()
		self.candidate_start_time = time.time()
		self.last_leader_msg = time.time()
		if not self.live_peers:
			# Single live node: self-elect immediately so progress continues.
			become_leader()
			return
		if self.live_peers:
			send(('PREPARE', self.ballot_num), to=self.live_peers)

# Conservative helper: follow known leader; if none, trigger election
	def ensure_leader():
		if self.status == 'LEADER':
			return True
		if self.current_leader and self.current_leader != self:
			return False
		start_election()
		return False

	def become_leader():
		self.status = 'LEADER'
		self.leader = self
		self.current_leader = self
		self.leader_grace_until = time.time() + ELECTION_TIMEOUT
		self.live_cluster_size = len(self.live_peers) + 1
		key = (self.ballot_num[0], self.ballot_num[1])
		for acc_log in self.promises.get(key, {}).values():
			self.accept_log.update(acc_log)
		self.new_view_messages.append(('NEW-VIEW', self.ballot_num, len(self.accept_log)))
		if self.live_peers:
			send(('HEARTBEAT', self.ballot_num, self), to=self.live_peers)
        
		# Process any backlogged PREPARED/DECISION messages captured while leader was unknown
		if self.backlog_prepared:
			pending_prepared = list(self.backlog_prepared)
			self.backlog_prepared.clear()
			for txid in pending_prepared:
				send(('PREPARED', txid), to=self)
		if self.backlog_decisions:
			pending_dec = list(self.backlog_decisions)
			self.backlog_decisions = []
			for txid, decision in pending_dec:
				send(('DECISION', txid, decision), to=self)
		if self.backlog_prepares:
			pending_preps = list(self.backlog_prepares)
			self.backlog_prepares = []
			for txid, tx, coord_shard, seq_p, seq_c in pending_preps:
				send(('PREPARE_TX', txid, tx, coord_shard, seq_p, seq_c), to=self)

	# === Paxos message handlers ===
	def receive(msg=('HEARTBEAT', b, leader_proc), from_=p):
		if self.is_failed:
			return
		if leader_proc == self.current_leader or b >= self.ballot_num:
			if b > self.ballot_num:
				self.ballot_num = b
			self.status = 'FOLLOWER'
			self.leader = leader_proc
			self.current_leader = leader_proc
			self.last_leader_msg = time.time()

	def receive(msg=('PREPARE', b), from_=p):
		if self.is_failed:
			return
		now = time.time()
		self.last_prepare_received_time = now
		if self.status == 'LEADER' and now < self.leader_grace_until:
			return
		if b >= self.ballot_num:
			accept_prepare(b, p)
			return
		if self.buffered_prepare is None or b > self.buffered_prepare[0]:
			self.buffered_prepare = (b, p)

	def accept_prepare(b, proposer):
		self.ballot_num = b
		self.status = 'FOLLOWER'
		self.leader = proposer
		self.current_leader = proposer
		self.candidate_start_time = 0.0
		self.buffered_prepare = None
		self.last_leader_msg = time.time()
		serialized_log = []
		for (ballot, seq, val) in self.accept_log:
			ballot_key = (ballot[0], ballot[1]) if isinstance(ballot, tuple) and len(ballot) >= 2 else ballot
			serialized_log.append((ballot_key, seq, val))
		b_key = (b[0], b[1]) if isinstance(b, tuple) and len(b) >= 2 else b
		send(('ACK', b_key, serialized_log), to=proposer)

	def receive(msg=('ACK', b, acc_log), from_=p):
		b_key = (b[0], b[1]) if len(b) >= 2 else b
		my_key = (self.ballot_num[0], self.ballot_num[1]) if len(self.ballot_num) >= 2 else self.ballot_num
		if isinstance(acc_log, list):
			acc_log = set(acc_log)
		if self.is_failed:
			return
		if self.status != 'CANDIDATE':
			if b_key != my_key:
				send(('PREPARE', self.ballot_num), to=p)
			return
		if b_key != my_key:
			send(('PREPARE', self.ballot_num), to=p)
			return
		if b_key not in self.promises:
			self.promises[b_key] = {}
		self.promises[b_key][p] = set(acc_log)
		majority = (self.live_cluster_size // 2) + 1
		if len(self.promises[b_key]) >= majority:
			become_leader()

	def receive(msg=('ACCEPT', b, seq, val), from_=leader):
		if self.is_failed:
			return
		if b < self.ballot_num:
			send(('NACK', (self.ballot_num[0], self.ballot_num[1])), to=leader)
			return
		self.ballot_num = b
		self.status = 'FOLLOWER'
		self.leader = leader
		self.current_leader = leader
		self.last_leader_msg = time.time()
		self.accept_log.add((b, seq, val))
		send(('ACCEPTED', b, seq, val, self), to=leader)

	def receive(msg=('NACK', b_key), from_=p):
		if self.status != 'LEADER':
			return
		my_key = (self.ballot_num[0], self.ballot_num[1])
		if b_key > my_key:
			self.status = 'FOLLOWER'
			self.last_leader_msg = time.time()

	def receive(msg=('ACCEPTED', b, seq, val, node), from_=_):
		if self.is_failed or self.status != 'LEADER':
			return
		key = (b, seq)
		voters = self.accepted_votes.setdefault(key, set())
		voters.add(node)
		if self not in voters:
			voters.add(self)
		if len(voters) > self.live_cluster_size / 2:
			existing = self.committed_log.get(seq)
			if existing and is_prep(existing) and is_decision(val):
				handle_commit(b, seq, val)
			elif not existing:
				handle_commit(b, seq, val)
				send(('COMMIT', b, seq, val), to=self.live_peers)

	def receive(msg=('COMMIT', b, seq, val), from_=_):
		handle_commit(b, seq, val)

	def handle_commit(b, seq, val):
		existing = self.committed_log.get(seq)
		if existing:
			if is_prep(existing) and is_decision(val):
				# Apply the decision even if a prepare already committed at this slot.
				self.committed_log[seq] = val
				_, txid, decision, role = val
				apply_decision_entry(txid, decision, role)
			return
		self.committed_log[seq] = val
		if seq > self.next_seq:
			self.next_seq = seq + 1
		execute_committed()

	def execute_committed():
		while self.last_executed + 1 in self.committed_log:
			seq = self.last_executed + 1
			val = self.committed_log[seq]
			apply_entry(val)
			self.last_executed = seq

	# === Application logic ===
	def is_prep(val):
		tag = val[0] if isinstance(val, tuple) else None
		return tag in ('2PC_PREP', '2PC_PREP_ABORT')

	def is_decision(val):
		tag = val[0] if isinstance(val, tuple) else None
		return tag == '2PC_DECISION'

	def apply_entry(val):
		tag = val[0] if isinstance(val, tuple) else None
		if tag == 'LOCAL':
			_, tx = val
			apply_local(tx)
		elif tag == '2PC_PREP':
			_, txid, tx, role = val
			apply_prepare_entry(txid, tx, role, commit_allowed=True)
		elif tag == '2PC_PREP_ABORT':
			_, txid, tx, role = val
			apply_prepare_entry(txid, tx, role, commit_allowed=False)
		elif tag == '2PC_DECISION':
			_, txid, decision, role = val
			apply_decision_entry(txid, decision, role)
		elif tag == 'NO-OP':
			pass

	def apply_local(tx):
		src, dst, amt = tx
		if src not in self.db:
			self.db[src] = 10
		if dst not in self.db:
			self.db[dst] = 10
		if self.db[src] < amt:
			return
		self.db[src] -= amt
		self.db[dst] += amt
		self.modified_keys.add(src)
		self.modified_keys.add(dst)

	def apply_prepare_entry(txid, tx, role, commit_allowed:bool):
		src, dst, amt = tx
		meta = self.tx_meta.setdefault(txid, {'tx': tx, 'prepared': {}, 'decision': None, 'prepare_seq': None, 'commit_seq': None, 'client': None, 'participants': ()})
		if commit_allowed:
			if role == 'COORD':
				record_wal(src, txid)
				self.db[src] = self.db.get(src, 10) - amt
				self.modified_keys.add(src)
			elif role == 'PART':
				record_wal(dst, txid)
				self.db[dst] = self.db.get(dst, 10) + amt
				self.modified_keys.add(dst)
		meta['prepared'][role] = commit_allowed
		self.tx_meta[txid] = meta
		if role == 'PART':
			coord_shard = meta.get('coord_shard')
			if coord_shard:
				targets = self.cluster_map.get(coord_shard, set())
				if targets:
					send(('PREPARED', txid), to=targets)
		if role == 'COORD' and self.status == 'LEADER' and meta['prepared'].get('PART') and not meta.get('decision'):
			decision = 'COMMIT'
			seq_c = meta.get('commit_seq', meta.get('prepare_seq', self.next_seq))
			propose_with_seq(seq_c, ('2PC_DECISION', txid, decision, 'COORD'))
			for shard in meta.get('participants', ()): 
				targets = self.cluster_map.get(shard, set())
				send(('DECISION', txid, decision), to=targets)
				self.decision_outbox[txid] = {'decision': decision, 'targets': set(targets), 'last_sent': time.time()}

	def apply_decision_entry(txid, decision, role):
		meta = self.tx_meta.get(txid)
		if not meta:
			return
		if meta.get('decision') and meta['decision'] == decision:
			return
		meta['decision'] = decision
		self.tx_meta[txid] = meta
		tx = meta.get('tx')
		if decision == 'COMMIT':
			release_locks(txid)
			if txid in self.wal:
				del self.wal[txid]
		else:
			undo_wal(txid)
			release_locks(txid)
		maybe_reply_client(txid, decision)
		if txid in self.pending_2pc:
			del self.pending_2pc[txid]
		if role == 'COORD' and txid in self.decision_outbox:
			del self.decision_outbox[txid]

	def cleanup_tx(txid):
		release_locks(txid)
		if txid in self.tx_table:
			del self.tx_table[txid]

	def maybe_reply_client(txid, decision):
		meta = self.tx_meta.get(txid)
		client = meta.get('client') if meta else None
		if client:
			send(('TX_RESULT', txid, decision), to=client)

	# === 2PC Handlers ===
	def receive(msg=('CLIENT_TX', tx, txid, client), from_=sender):
		if self.is_failed:
			return
		if self.status != 'LEADER':
			ensure_leader()
			if self.status != 'LEADER':
				self.pending_requests.add((txid, tx, client))
				return
		handle_client_tx(tx, txid, client)

	def handle_client_tx(tx, txid, client):
		# Skip if we already processed this request
		if txid in self.tx_client:
			return
		if len(tx) == 1:
			cid = tx[0]
			bal = self.db.get(cid, 10)
			send(('TX_RESULT', txid, ('BAL', bal)), to=client)
			self.tx_client[txid] = client
			return
		src, dst, amt = tx
		shard_src = shard_for(src)
		shard_dst = shard_for(dst)
		if shard_src == self.cluster_id and shard_dst == self.cluster_id:
			sender_bal = self.db.get(src, 10)
			if sender_bal < amt:
				send(('TX_RESULT', txid, 'ABORT'), to=client)
				self.tx_client[txid] = client
				return
			propose(('LOCAL', tx))
			send(('TX_RESULT', txid, 'COMMIT'), to=client)
			self.tx_client[txid] = client
			return
		participants = (shard_dst,)
		if not acquire_lock(src, txid):
			send(('TX_RESULT', txid, 'ABORT'), to=client)
			self.tx_client[txid] = client
			return
		sender_bal = self.db.get(src, 10)
		if sender_bal < amt:
			release_locks(txid)
			send(('TX_RESULT', txid, 'ABORT'), to=client)
			self.tx_client[txid] = client
			return
		seq_p = self.next_seq
		self.tx_meta[txid] = {'tx': tx, 'prepared': {}, 'decision': None, 'prepare_seq': seq_p, 'commit_seq': seq_p, 'client': client, 'participants': participants, 'ts': time.time()}
		self.tx_client[txid] = client
		propose_with_seq(seq_p, ('2PC_PREP', txid, tx, 'COORD'))
		targets = self.cluster_map.get(shard_dst, set())
		send(('PREPARE_TX', txid, tx, self.cluster_id, seq_p, seq_p), to=targets)
		self.pending_2pc[txid] = {'state': 'WAIT_PREPARED', 'ts': time.time(), 'seq_p': seq_p, 'participants': set(participants), 'participants_ready': set(), 'last_prepare_sent': time.time()}

	def acquire_lock(key, txid):
		holder = self.locks.get(key)
		if holder and holder != txid:
			return False
		self.locks[key] = txid
		if key not in self.db:
			self.db[key] = 10
		return True

	def release_locks(txid):
		for k, v in list(self.locks.items()):
			if v == txid:
				del self.locks[k]

	def record_wal(key, txid):
		prev = self.db.get(key, 10)
		self.wal.setdefault(txid, []).append((key, prev))
		self.modified_keys.add(key)

	def undo_wal(txid):
		for key, prev in self.wal.get(txid, []):
			self.db[key] = prev
			self.modified_keys.add(key)
		if txid in self.wal:
			del self.wal[txid]

	def receive(msg=('PREPARE_TX', txid, tx, coord_shard, seq_p, seq_c), from_=leader):
		if self.is_failed:
			return
		if self.status != 'LEADER':
			self.backlog_prepares.append((txid, tx, coord_shard, seq_p, seq_c))
			ensure_leader()
			return
		src, dst, amt = tx
		coord_targets = self.cluster_map.get(coord_shard, set())
		if not acquire_lock(dst, txid):
			propose_with_seq(seq_p, ('2PC_PREP_ABORT', txid, tx, 'PART'))
			send(('ABORT_TX', txid), to=coord_targets)
			return
		self.tx_meta[txid] = {'tx': tx, 'prepared': {}, 'decision': None, 'prepare_seq': seq_p, 'commit_seq': seq_p, 'client': None, 'participants': (self.cluster_id,), 'ts': time.time(), 'coord_shard': coord_shard}
		propose_with_seq(seq_p, ('2PC_PREP', txid, tx, 'PART'))

	def receive(msg=('PREPARED', txid), from_=p):
		meta = self.tx_meta.get(txid)
		if not meta:
			return
		if meta.get('decision'):
			return
		meta.setdefault('prepared', {})['PART'] = True
		self.tx_meta[txid] = meta
		if txid in self.pending_2pc:
			self.pending_2pc[txid].setdefault('participants_ready', set()).add(meta.get('participants', ())[0])
		coord_shard = meta.get('coord_shard')
		coord_targets = self.cluster_map.get(coord_shard, set()) if coord_shard else set()
		if coord_targets:
			send(('PREPARED', txid), to=coord_targets)
		if self.status != 'LEADER':
			fresh = self.current_leader if (self.current_leader and (time.time() - self.last_leader_msg) < HEARTBEAT_TIMEOUT) else None
			if not fresh:
				self.backlog_prepared.add(txid)
				ensure_leader()
			return
		if meta['prepared'].get('COORD') and not meta.get('decision'):
			decision = 'COMMIT'
			seq_c = meta.get('commit_seq') or meta.get('prepare_seq') or self.next_seq
			propose_with_seq(seq_c, ('2PC_DECISION', txid, decision, 'COORD'))
			participant_shards = meta.get('participants', ())
			client = meta.get('client')
			for shard in participant_shards:
				targets = self.cluster_map.get(shard, set())
				send(('DECISION', txid, decision), to=targets)
				self.decision_outbox[txid] = {'decision': decision, 'targets': set(targets), 'last_sent': time.time(), 'client': client}
			if client:
				send(('TX_RESULT', txid, decision), to=client)

	def receive(msg=('ABORT_TX', txid), from_=p):
		meta = self.tx_meta.get(txid)
		if not meta:
			return
		if self.status != 'LEADER':
			coord_targets = self.cluster_map.get(meta.get('coord_shard'), set()) if meta else set()
			if coord_targets:
				send(('ABORT_TX', txid), to=coord_targets)
			fresh = self.current_leader if (self.current_leader and (time.time() - self.last_leader_msg) < HEARTBEAT_TIMEOUT) else None
			if not fresh:
				self.backlog_decisions.append((txid, 'ABORT'))
				ensure_leader()
			return
		decision = 'ABORT'
		seq_c = meta.get('commit_seq') or meta.get('prepare_seq') or self.next_seq
		propose_with_seq(seq_c, ('2PC_DECISION', txid, decision, 'COORD'))
		participant_shards = meta.get('participants', ())
		client = meta.get('client')
		for shard in participant_shards:
			targets = self.cluster_map.get(shard, set())
			send(('DECISION', txid, decision), to=targets)
			self.decision_outbox[txid] = {'decision': decision, 'targets': set(targets), 'last_sent': time.time(), 'client': client}
		if client:
			send(('TX_RESULT', txid, decision), to=client)

	def receive(msg=('DECISION', txid, decision), from_=coord):
		meta = self.tx_meta.get(txid)
		if not meta:
			# Create a stub so we can honor the decision and ack; avoids losing coord replies
			meta = {'tx': None, 'prepared': {}, 'decision': None, 'prepare_seq': None, 'commit_seq': None, 'client': None, 'participants': (), 'coord_shard': None}
			self.tx_meta[txid] = meta
		if meta.get('decision'):
			return
		if self.status != 'LEADER':
			self.backlog_decisions.append((txid, decision))
			ensure_leader()
			return
		seq_c = meta.get('commit_seq') or meta.get('prepare_seq') or self.next_seq
		propose_with_seq(seq_c, ('2PC_DECISION', txid, decision, 'PART'))
		maybe_reply_client(txid, decision)
		send(('DECISION_ACK', txid), to=coord)

	def receive(msg=('DECISION_ACK', txid), from_=p):
		if txid in self.decision_outbox:
			del self.decision_outbox[txid]

	# === Paxos propose ===
	def propose(val):
		seq = self.next_seq
		self.next_seq += 1
		self.accept_log.add((self.ballot_num, seq, val))
		send(('ACCEPT', self.ballot_num, seq, val), to=self.live_peers)
		send(('ACCEPTED', self.ballot_num, seq, val, self), to=self)

	def propose_with_seq(seq, val):
		if seq >= self.next_seq:
			self.next_seq = seq + 1
		self.accept_log.add((self.ballot_num, seq, val))
		send(('ACCEPT', self.ballot_num, seq, val), to=self.live_peers)
		send(('ACCEPTED', self.ballot_num, seq, val, self), to=self)

	# === Failure and control ===
	def receive(msg=('FAIL',)):
		self.is_failed = True
		for peer in self.live_peers:
			send(('PEER_FAILED', self), to=peer)

	def receive(msg=('RECOVER',)):
		self.is_failed = False
		self.last_leader_msg = time.time()
		for peer in self.live_peers:
			send(('PEER_RECOVERED', self), to=peer)

	def receive(msg=('PEER_FAILED', p), from_=_):
		if p in self.live_peers:
			self.live_peers.discard(p)
			self.live_cluster_size = len(self.live_peers) + 1

	def receive(msg=('PEER_RECOVERED', p), from_=_):
		if p not in self.live_peers and p != self:
			self.live_peers.add(p)
			self.live_cluster_size = len(self.live_peers) + 1

	def receive(msg=('RESET',)):
		self.accept_log = set()
		self.committed_log = {}
		self.accepted_votes = {}
		self.promises = {}
		self.next_seq = 1
		self.last_executed = 0
		self.db.reset()
		self.modified_keys = set()
		self.locks = {}
		self.tx_table = {}
		self.tx_meta = {}
		self.wal = {}
		self.decision_outbox = {}
		self.pending_2pc = {}
		self.tx_client = {}
		self.backlog_prepared = set()
		self.backlog_decisions = []
		self.backlog_prepares = []
		self.new_view_messages = []
		self.status = 'LEADER' if self.is_initial_leader else 'FOLLOWER'
		self.ballot_num = (1, self.node_name, self) if self.is_initial_leader else (0, self.node_name, self)
		self.leader = self if self.is_initial_leader else self.initial_leader_proc
		self.current_leader = self.leader
		self.live_peers = set(self.peers)
		self.live_cluster_size = len(self.live_peers) + 1
		self.last_leader_msg = time.time()

	def receive(msg=('PRINT_DB', set_id)):
		if not self.modified_keys:
			output(f"Set {set_id} {self.node_name} DB: []")
			return
		pairs = []
		for k in sorted(self.modified_keys):
			pairs.append(f"{k}:{self.db.get(k, INITIAL_BALANCE)}")
		changed = ", ".join(pairs)
		output(f"Set {set_id} {self.node_name} DB: {changed}")

	def receive(msg=('PRINT_VIEW', set_id)):
		for nv in self.new_view_messages:
			output(f"Set {set_id} {self.node_name} View: {nv}")

	def receive(msg=('PRINT_BALANCE', key_id)):
		bal = self.db.get(key_id, 10)
		output(f"{self.node_name} : {bal}")

	def receive(msg=('PRINT_RESHARD',)):
		output(f"{self.node_name} RESHARD: []")

	def receive(msg=('STOP',)):
		self.shutdown = True


# === Parsing ===
def read_tests(csv_file):
	test_sets = []
	current = None
	with open(csv_file, 'r') as f:
		reader = csv.reader(f)
		next(reader, None)
		for row in reader:
			if not row or len(row) < 2:
				continue
			set_num = row[0].strip()
			tx_str = row[1].strip()
			live_nodes_str = row[2].strip() if len(row) > 2 else ''

			if set_num:
				if current:
					test_sets.append(current)
				current = {'id': set_num, 'transactions': [], 'live_nodes': parse_live_nodes(live_nodes_str)}

			if not current:
				continue

			if tx_str:
				if tx_str.startswith('F(') and tx_str.endswith(')'):
					current['transactions'].append(('FAIL', tx_str[2:-1]))
				elif tx_str.startswith('R(') and tx_str.endswith(')'):
					current['transactions'].append(('RECOVER', tx_str[2:-1]))
				else:
					tx = parse_transaction(tx_str)
					if tx:
						current['transactions'].append(('TX', tx))

		if current:
			test_sets.append(current)
	return test_sets


def main():
	csv_arg = sys.argv[1] if len(sys.argv) > 1 else 'CSE535-F25-Project-3-Testcases.csv'
	log_info(f"Using test file: {csv_arg}")

	node_names = ['n1','n2','n3','n4','n5','n6','n7','n8','n9']
	nodes = new(Node, num=9)
	nodes_list = list(nodes)

	node_map = {name: proc for name, proc in zip(node_names, nodes_list)}
	cluster_map = {
		1: set(nodes_list[0:3]),
		2: set(nodes_list[3:6]),
		3: set(nodes_list[6:9])
	}
	leader_lookup = {'n1': node_map['n1'], 'n4': node_map['n4'], 'n7': node_map['n7']}
	cluster_leaders = {1: leader_lookup['n1'], 2: leader_lookup['n4'], 3: leader_lookup['n7']}

	for i, node in enumerate(nodes_list):
		name = node_names[i]
		cid = 1 if i < 3 else (2 if i < 6 else 3)
		peers = cluster_map[cid]
		initial_leader = name in ['n1', 'n4', 'n7']
		initial_leader_proc = leader_lookup['n1'] if cid == 1 else (leader_lookup['n4'] if cid == 2 else leader_lookup['n7'])
		setup(node, (name, cid, peers, set(nodes_list), cluster_map, initial_leader, initial_leader_proc))

	start(nodes)

	driver = new(Driver, num=1)
	setup(driver, (csv_arg, node_map, cluster_map, cluster_leaders))
	start(driver)

	# Main returns; runtime will join child processes

