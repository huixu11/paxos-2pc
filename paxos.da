import sys
import time
import csv
import random
import threading

# Configuration
TIMEOUT = 5.0  # Shorter to improve runtime while keeping quorum progress
HEARTBEAT_INTERVAL = 0.5
HEARTBEAT_TIMEOUT = 1.0  # Reduced from 3.0 for faster leader election after LF
ELECTION_TIMEOUT = 1.5  # t: follower timer reset by leader traffic
PREPARE_BACKOFF = 0.6   # tp: suppress competing prepares seen very recently
ELECTION_JITTER = 0.3   # small jitter to avoid simultaneous elections



# Helper Functions
def parse_transaction(tx_str):
    """Parse transaction string like '(A, B, 10)' or '(A)'"""
    if not tx_str or tx_str.strip() == '': 
        return None
    tx_str = tx_str.strip().strip('()')
    parts = [p.strip() for p in tx_str.split(',')]
    if len(parts) == 3:
        return (parts[0], parts[1], int(parts[2]))
    elif len(parts) == 1:
        return (parts[0],)
    return None

def parse_live_nodes(nodes_str):
    """Parse live nodes string like '[n1, n2, n3]'"""
    if not nodes_str or nodes_str.strip() == '':
        return []
    nodes_str = nodes_str.strip().strip('[]')
    return [n.strip() for n in nodes_str.split(',')]

# Client Process
class Client(process):
    def setup(client_id:int, nodes:set, initial_leader):
        self.client_id = client_id
        self.nodes = nodes
        self.leader = initial_leader
        self.request_id = 0
        self.pending = None  # (req_id, tx, timestamp)
        # Minimal startup log
        output(f"Client {client_id} setup with leader {initial_leader}")
    
    def run():
        # Client run loop idle until DONE
        output("Client started running")
        await(some(received(('DONE',))))
        output("Client finishing")
    
    def receive(msg=('TRIGGER_TX', tx), from_=parent):
        output(f"Client triggered for {tx}")
        result = request_transaction(tx)
        output(f"Client completed {tx} with result {result}")
        send(('TX_RESULT', tx, result), to=parent)
    
    def request_transaction(tx):
        self.request_id += 1
        req_id = (self.client_id, self.request_id)
        timestamp = time.time()
        self.pending = (req_id, tx, timestamp)
        
        attempts = 0
        wait_interval = TIMEOUT  # base retry interval
        
        while True:
            # Broadcast to all known nodes to ensure delivery even if leader fails
            send(('CLIENT_REQUEST', tx, timestamp, self.client_id, req_id, self), to=self.nodes)

            # Start a per-attempt timer that sends a local timeout message
            attempt_id = attempts
            timer = threading.Timer(wait_interval, lambda: send(('CLIENT_TIMEOUT', req_id, attempt_id), to=self))
            timer.start()

            if await(some(received(('CLIENT_REPLY', r_id, _), from_=sender_proc), has= r_id == req_id) or some(received(('CLIENT_TIMEOUT', t_id, t_attempt)), has= t_id == req_id and t_attempt == attempts)):
                replies = setof((p, res), received(('CLIENT_REPLY', r_id, res), from_=p), r_id == req_id)
                if replies:
                    timer.cancel()
                    new_leader, result = replies.pop()
                    output(f"Client received reply for {req_id} from {new_leader}: {result}")
                    self.leader = new_leader
                    self.pending = None
                    return result
            
            timer.cancel()
            attempts += 1
            # If we have been retrying for a while, nudge nodes to elect a leader
            if attempts % 3 == 0:
                send(('FORCE_ELECTION',), to=self.nodes)
            continue

# Driver process to orchestrate test sets with proper awaits
class Driver(process):
    def setup(test_sets:list, node_names:list, node_map:dict, nodes:set, client_proc, all_clients:set):
        self.test_sets = test_sets
        self.node_names = node_names
        self.node_map = node_map
        self.nodes = nodes
        self.client = client_proc
        self.all_clients = all_clients
    
    def run():
        # Initialize known clients/balances on all nodes
        if self.all_clients:
            send(('INIT_CLIENTS', list(self.all_clients)), to=self.nodes)
        
        for test_set in self.test_sets:
            output(f"\n=== Processing Set {test_set['id']} ===")
            
            # Handle live nodes and track current live set
            if test_set['live_nodes']:
                live_nodes_set = set(test_set['live_nodes'])
                for name in self.node_names:
                    if name in live_nodes_set:
                        send(('RECOVER',), to=self.node_map[name])
                    else:
                        send(('FAIL',), to=self.node_map[name])
            else:
                live_nodes_set = set(self.node_names)
                send(('RECOVER',), to=self.nodes)

            # Inform nodes of current live set for majority calculations and messaging
            live_procs = set(self.node_map[n] for n in live_nodes_set)
            send(('SET_LIVE', live_procs), to=self.nodes)

            # Give RECOVER/FAIL a brief window to settle
            time.sleep(TIMEOUT * 0.05)
            
            def live_count():
                return len(live_nodes_set)
            
            def update_quorum():
                q = live_count() >= 3
                if q:
                    send(('RESUME_QUORUM',), to=self.nodes)
                else:
                    send(('PAUSE_NO_QUORUM',), to=self.nodes)
                return q
            
            quorum_met = update_quorum()
            if not quorum_met:
                output(f"WARNING: Only {live_count()} live nodes - Quorum NOT met, skipping transactions")
            
            current_leader_name = sorted(list(live_nodes_set))[0] if live_nodes_set else None
            
            # Process transactions sequentially
            for tx_type, tx_data in test_set['transactions']:
                if tx_type == 'FAIL':
                    send(('FAIL',), to=self.node_map[tx_data])
                    live_nodes_set.discard(tx_data)
                    quorum_met = update_quorum()
                elif tx_type == 'RECOVER':
                    send(('RECOVER',), to=self.node_map[tx_data])
                    live_nodes_set.add(tx_data)
                    quorum_met = update_quorum()
                elif tx_type == 'TX':
                    if tx_data == ('LF',):
                        output("Executing LF (Leader Fail)")
                        leader_to_fail = None
                        if current_leader_name and current_leader_name in live_nodes_set:
                            leader_to_fail = current_leader_name
                        elif live_nodes_set:
                            leader_to_fail = sorted(list(live_nodes_set))[0]
                        
                        if leader_to_fail:
                            send(('FAIL_LEADER',), to=self.node_map[leader_to_fail])
                            live_nodes_set.discard(leader_to_fail)
                            output(f"LF killed leader {leader_to_fail}")
                        
                        # Trigger election among remaining live nodes only
                        live_procs = set(self.node_map[n] for n in live_nodes_set)
                        if live_procs:
                            send(('FORCE_ELECTION',), to=live_procs)
                        
                        quorum_met = update_quorum()
                        if not quorum_met:
                            output(f"WARNING: LF reduced live nodes to {live_count()} - Quorum NOT met, remaining TX skipped")
                        else:
                            current_leader_name = sorted(list(live_nodes_set))[0] if live_nodes_set else None
                        # Give the cluster time to elect a new leader before next request
                        time.sleep(TIMEOUT * 0.5)
                        continue
                    
                    if not quorum_met:
                        output(f"Tx {tx_data} -> SKIPPED (no quorum)")
                        continue
                    
                    send(('TRIGGER_TX', tx_data), to=self.client)
                    
                    await(some(received(('TX_RESULT', tx_val, res)), has= tx_val == tx_data))
                    results = setof(res, received(('TX_RESULT', tx_val, res)), tx_val == tx_data)
                    result = results.pop()
                    output(f"Tx {tx_data} -> {result}")
            
            # Short settle, then print DB
            time.sleep(TIMEOUT * 0.05)
            output(f"\n=== End of Set {test_set['id']} ===")
            send(('PRINT_DB',), to=self.nodes)
            time.sleep(0.5)
        
        # Cleanup
        send(('DONE',), to=self.client)
        send(('STOP',), to=self.nodes)

# Node Process
class Node(process):
    def setup(node_name:str, peers:set, is_initial_leader:bool):
        self.node_name = node_name
        self.cluster_size = len(peers)  # Total cluster size for quorum checks
        self.peers = peers - {self}
        self.live_peers = set(self.peers)
        self.live_cluster_size = len(peers)
        self.shutdown = False
        
        # Paxos state
        self.is_initial_leader = is_initial_leader
        self.ballot_num = (1, self) if is_initial_leader else (0, self)
        self.status = 'LEADER' if is_initial_leader else 'FOLLOWER'
        self.leader = self if is_initial_leader else None
        self.current_leader = self if is_initial_leader else None  # Track current leader

        
        # Logs
        self.accept_log = set()  # Set of (ballot, seq, val)
        self.committed_log = {}  # seq -> val
        # Gap recovery tracking: (start,end) -> first request time
        self.pending_gap_requests = {}
        
        # Leader election
        self.promises = {}  # ballot -> {node -> accept_log}
        self.accepted_votes = {}  # (ballot, seq) -> set of nodes
        
        # Sequence numbers
        self.next_seq = 1
        self.last_executed_seq = 0
        
        # Database
        self.db = {}  # client_id -> balance (default 10)
        self.known_clients = set()  # Track all clients seen

        
        # Client tracking for exactly-once
        self.client_replies = {}  # (client_id, req_id) -> (client_proc, result)
        self.pending_requests = set()  # Set of (client_id, req_id) being processed
        self.sent_replies = set()      # Track replies already sent to clients
        
        # Failure state
        self.is_failed = False
        self.recover_quiet_until = 0.0  # Suppress elections right after recovery
        self.pause_no_quorum = False    # Pause elections/heartbeats when cluster lacks quorum

        # Election timers/backoff
        self.last_leader_msg = time.time()
        self.buffered_prepare = None  # Highest PREPARE seen while timer active
        self.last_prepare_received_time = 0.0
        
        # For PrintView
        self.new_view_messages = []
    
    def run():
        while not self.shutdown:
            if self.is_failed:
                if self.shutdown:
                    break
                await(not self.is_failed)
                continue
            
            # Leader sends heartbeats
            if self.status == 'LEADER':
                if self.pause_no_quorum:
                    await(self.pause_no_quorum == False)
                    continue
                send(('HEARTBEAT', self.ballot_num, self), to=self.live_peers)
                
                if await(some(received(_))):
                    pass
                elif timeout(HEARTBEAT_INTERVAL):
                    pass
            
            # Follower checks for heartbeat timeout
            elif self.status == 'FOLLOWER':
                # When cluster is below quorum or this node is failed, stay silent
                if self.is_failed or self.pause_no_quorum:
                    await(self.pause_no_quorum == False and self.is_failed == False)
                    continue
                old_timer = self.last_leader_msg
                jitter = random.uniform(0, ELECTION_JITTER)
                to_wait = (ELECTION_TIMEOUT + jitter) - (time.time() - old_timer)
                if to_wait < 0:
                    to_wait = 0
                
                if await(self.last_leader_msg > old_timer):
                    pass
                elif timeout(to_wait):
                    handle_timer_expiry()
            
            else:  # CANDIDATE
                await(some(received(_)))
    
    # === Leader Election ===
    
    def timer_has_expired():
        return (time.time() - self.last_leader_msg) >= ELECTION_TIMEOUT
    
    def handle_timer_expiry():
        if self.is_failed:
            return
        if time.time() < self.recover_quiet_until:
            return
        if self.pause_no_quorum:
            return
        
        # Honor any buffered PREPARE with the highest ballot seen so far
        if self.buffered_prepare:
            b, proposer = self.buffered_prepare
            self.buffered_prepare = None
            if b > self.ballot_num:
                accept_prepare(b, proposer)
                return
        
        now = time.time()
        # Avoid dueling leaders if we've recently seen another PREPARE
        if (now - self.last_prepare_received_time) < PREPARE_BACKOFF:
            self.status = 'FOLLOWER'
            return
        
        start_election()
    
    def start_election():
        if self.is_failed:
            return
        
        now = time.time()
        if (now - self.last_prepare_received_time) < PREPARE_BACKOFF:
            output(f"{self.node_name} skipping PREPARE broadcast (backoff window)")
            self.status = 'FOLLOWER'
            return
        
        self.status = 'CANDIDATE'
        self.ballot_num = (self.ballot_num[0] + 1, self)
        self.promises[self.ballot_num] = {self: set(self.accept_log)}
        
        send(('PREPARE', self.ballot_num), to=self.live_peers)
    
    def receive(msg=('PREPARE', b), from_=p):
        if self.is_failed:
            return
        
        self.last_prepare_received_time = time.time()
        
        # Respond immediately to higher ballots to avoid election stalls
        if b > self.ballot_num:
            accept_prepare(b, p)
        else:
            # Buffer the highest PREPARE seen while the timer is still active
            if self.buffered_prepare is None or b > self.buffered_prepare[0]:
                self.buffered_prepare = (b, p)
    
    def accept_prepare(b, proposer):
        self.ballot_num = b
        self.status = 'FOLLOWER'
        self.leader = proposer
        self.current_leader = proposer
        self.buffered_prepare = None
        self.last_leader_msg = time.time()
        send(('ACK', b, set(self.accept_log)), to=proposer)
    
    def receive(msg=('ACK', b, acc_log), from_=p):
        if self.is_failed or self.status != 'CANDIDATE' or b != self.ballot_num:
            return
        
        # output(f"{self.node_name} received ACK from {p}")
        
        self.promises[b][p] = set(acc_log)
        
        # Check for majority
        majority = (self.live_cluster_size // 2) + 1
        if len(self.promises[b]) >= majority:
            output(f"{self.node_name} got majority promises! Becoming leader.")
            become_leader()
    
    def become_leader():
        self.status = 'LEADER'
        self.leader = self
        self.current_leader = self  # Track current leader
        self.accepted_votes = {}  # Reset vote tracking for new view
        
        # Construct NEW-VIEW from quorum AcceptLogs
        all_entries = set()
        for acc_log in self.promises[self.ballot_num].values():
            all_entries.update(acc_log)
        all_entries.update(self.accept_log)
        
        max_seq = max([e[1] for e in all_entries]) if all_entries else 0
        
        # Fill gaps with no-op and choose highest-ballot entry per seq
        new_log = set()
        for s in range(1, max_seq + 1):
            entries_at_s = [e for e in all_entries if e[1] == s]
            if entries_at_s:
                best = max(entries_at_s)  # Highest ballot wins
                chosen_val = best[2]
            else:
                chosen_val = 'NO-OP'
            new_log.add((self.ballot_num, s, chosen_val))
        
        self.accept_log = new_log
        self.next_seq = max_seq + 1
        
        # Vote for own proposals in NEW-VIEW
        for (ballot, seq, val) in new_log:
            key = (ballot, seq)
            self.accepted_votes[key] = {self}
        
        output(f"Leader {self.node_name} NEW-VIEW: {len(new_log)} entries, seq range 1-{max_seq}")
        
        # Send NEW-VIEW
        ordered_new_log = sorted(new_log, key=lambda e: e[1])
        nv_msg = ('NEW-VIEW', self.ballot_num, ordered_new_log)
        self.new_view_messages.append(nv_msg)
        send(nv_msg, to=self.live_peers)
        # Also send ACCEPT to ensure peers record values even if they ignore NEW-VIEW
        for (_, seq, val) in ordered_new_log:
            send(('ACCEPT', self.ballot_num, seq, val), to=self.live_peers)
            send(('ACCEPTED', self.ballot_num, seq, val, self), to=self)
    
    def receive(msg=('NEW-VIEW', b, new_log), from_=leader):
        if self.is_failed:
            return
        
        if b >= self.ballot_num:
            output(f"{self.node_name} received NEW-VIEW from {leader}: {len(new_log)} entries")
            self.ballot_num = b
            self.status = 'FOLLOWER'
            self.leader = leader
            self.current_leader = leader
            self.accept_log = set(new_log)
            if new_log:
                self.next_seq = max(e[1] for e in new_log) + 1
            self.last_leader_msg = time.time()
            self.buffered_prepare = None
            self.new_view_messages.append(('NEW-VIEW', b, new_log))
            
            # Treat as Accept messages, send ACCEPTED, do not commit/execute yet
            for (ballot, seq, val) in new_log:
                send(('ACCEPTED', ballot, seq, val, self), to=leader)
    
    # === Heartbeat ===
    
    def receive(msg=('HEARTBEAT', b, leader_proc), from_=p):

        if self.is_failed:
            return
        if self.pause_no_quorum:
            return
        
        if b >= self.ballot_num:
            self.ballot_num = b

            self.leader = leader_proc

            self.current_leader = leader_proc  # Track current leader

            self.last_leader_msg = time.time()

            self.status = 'FOLLOWER'

    # === Normal Operations ===
    
    def receive(msg=('CLIENT_REQUEST', tx, timestamp, cid, req_id, client_proc), from_=client_sender):
        if self.is_failed:
            return
        
        # Suppress verbose request logs; keep minimal errors
        
        # Check if already processed
        if (cid, req_id) in self.client_replies:
            saved_client_proc, result = self.client_replies[(cid, req_id)]
            send(('CLIENT_REPLY', req_id, result), to=saved_client_proc)
            return
        
        # Forward to leader if not leader
        if self.status != 'LEADER':
            # Always broadcast to peers to ensure some leader candidate receives it
            send(('CLIENT_REQUEST', tx, timestamp, cid, req_id, client_proc), to=self.live_peers)
            # If no known leader, kick off election locally
            if self.leader is None:
                start_election()
            return
        
        # Check if already being processed (pending)
        if (cid, req_id) in self.pending_requests:
            return
        
        # Mark as pending
        self.pending_requests.add((cid, req_id))
        
        # Leader: propose transaction
        seq = self.next_seq
        self.next_seq += 1
        
        # Store client process in value so we can reply later
        val = (tx, timestamp, cid, req_id, client_proc)
        self.accept_log.add((self.ballot_num, seq, val))
        
        send(('ACCEPT', self.ballot_num, seq, val), to=self.live_peers)
        # Self-vote
        send(('ACCEPTED', self.ballot_num, seq, val, self), to=self)
    
    def receive(msg=('ACCEPT', b, seq, val), from_=leader):
        if self.is_failed:
            return
        
        if b >= self.ballot_num:
            self.ballot_num = b
            self.leader = leader
            self.current_leader = leader
            self.last_leader_msg = time.time()
            self.accept_log.add((b, seq, val))
            send(('ACCEPTED', b, seq, val, self), to=leader)
    
    def receive(msg=('ACCEPTED', b, seq, val, node), from_=_):
        if self.is_failed or self.status != 'LEADER' or b != self.ballot_num:
            return
        # Ignore if already committed/executed
        if seq in self.committed_log or seq <= self.last_executed_seq:
            return
        
        key = (b, seq)
        if key not in self.accepted_votes:
            self.accepted_votes[key] = set()
        
        self.accepted_votes[key].add(node)
        
        # Check for majority based on live cluster size
        if len(self.accepted_votes[key]) > self.live_cluster_size / 2:
            # Commit
            send(('COMMIT', b, seq, val), to=self.live_peers)
            output(f"Leader {self.node_name} committing {seq}")
            # Self-commit
            handle_commit(b, seq, val)
    
    def receive(msg=('COMMIT', b, seq, val), from_=_):
        if self.is_failed:
            return
        
        if b > self.ballot_num:
            self.ballot_num = b
        self.last_leader_msg = time.time()
        handle_commit(b, seq, val)
    
    def handle_commit(b, seq, val):
        # Skip if already executed (happens during NEW-VIEW sync)
        if seq <= self.last_executed_seq:
            output(f"{self.node_name} SKIPPING already-executed seq={seq}")
            return

        # Detect and request any gap before this commit
        expected_seq = self.last_executed_seq + 1
        if seq > expected_seq:
            request_missing_slots(expected_seq, seq - 1)

        self.committed_log[seq] = val
        # Commit log; executed output handled in execute_committed
        execute_committed()

    def execute_committed():
        """Execute all committed transactions in order"""
        # If we see future commits but are missing the next one, actively fetch it.
        if self.committed_log:
            expected = self.last_executed_seq + 1
            highest_seen = max(self.committed_log.keys())
            if expected <= highest_seen and expected not in self.committed_log:
                request_missing_slots(expected, expected)

        while self.last_executed_seq + 1 in self.committed_log:
            seq = self.last_executed_seq + 1
            val = self.committed_log[seq]

            if val == 'NO-OP':
                self.last_executed_seq = seq
                continue
            
            # val is (tx, timestamp, cid, req_id, client_proc)
            tx, timestamp, cid, req_id, client_proc = val
            
            # Execute transaction
            if len(tx) == 3:  # Transfer (sender, receiver, amount)
                sender, receiver, amount = tx
                self.known_clients.add(sender)
                self.known_clients.add(receiver)
                
                sender_bal = self.db.get(sender, 10)
                receiver_bal = self.db.get(receiver, 10)
                
                if sender_bal >= amount:
                    self.db[sender] = sender_bal - amount
                    self.db[receiver] = receiver_bal + amount
                    result = "SUCCESS"
                else:
                    result = "INSUFFICIENT_FUNDS"
            
            elif len(tx) == 1:  # Balance query
                client_id = tx[0]
                self.known_clients.add(client_id)
                balance = self.db.get(client_id, 10)
                result = f"BALANCE:{balance}"
            
            else:
                result = "UNKNOWN_TX"
            
            output(f"{self.node_name} EXECUTED seq={seq}, tx={tx}, result={result}")
            
            # Store result for exactly-once (store client_proc and result)
            self.client_replies[(cid, req_id)] = (client_proc, result)
            
            # Remove from pending set
            self.pending_requests.discard((cid, req_id))
            
            # Send reply (leader or backup) once
            if (cid, req_id) not in self.sent_replies:
                # Debug: trace replies to verify client sees them
                output(f"{self.node_name} sending CLIENT_REPLY for {req_id} result={result} to {client_proc}")
                send(('CLIENT_REPLY', req_id, result), to=client_proc)
                self.sent_replies.add((cid, req_id))
            
            self.last_executed_seq = seq
    
    # === Failure Handling ===
    
    def receive(msg=('FAIL',)):
        self.is_failed = True
        output(f"{self.node_name} FAILED (is_failed=True)")
        
    def receive(msg=('FAIL_LEADER',)):
        if self.status == 'LEADER':
            self.is_failed = True
            output(f"{self.node_name} (LEADER) FAILED by LF command")

    def receive(msg=('STOP',)):
        # Graceful shutdown after driver completes
        self.shutdown = True
        self.is_failed = True
        self.pause_no_quorum = True
    def receive(msg=('LEADER_FAILED', failed_leader)):

        # Immediate view change when leader failed

        if not self.is_failed and failed_leader == self.current_leader and self.status != 'LEADER':

            output(f"{self.node_name} detected leader {failed_leader} failed! Triggering immediate election.")

            start_election()

    def receive(msg=('FORCE_ELECTION',)):
        if self.is_failed:
            return
        # Force a new election without killing the node
        self.status = 'FOLLOWER'
        self.buffered_prepare = None
        self.last_leader_msg = 0.0
        start_election()
    

    def receive(msg=('RECOVER',)):
        output(f"{self.node_name} RECOVERING (last_executed={self.last_executed_seq}, db_size={len(self.db)})")
        self.is_failed = False
        self.last_leader_msg = time.time()
        self.buffered_prepare = None
        self.recover_quiet_until = time.time() + (TIMEOUT * 0.5)
        # Actively request missing commits since leader may not change
        send(('CATCHUP_REQUEST', self.last_executed_seq, self), to=self.peers)

        # No need for active catch-up - NEW-VIEW will synchronize state
        # send(('CATCHUP_REQUEST', self.last_executed_seq, self), to=self.peers)

    def receive(msg=('PAUSE_NO_QUORUM',)):
        self.pause_no_quorum = True
        self.last_leader_msg = time.time()
        self.buffered_prepare = None

    def receive(msg=('RESUME_QUORUM',)):
        self.pause_no_quorum = False
        self.last_leader_msg = time.time()

    def request_missing_slots(start_seq, end_seq):
        """Actively request missing committed slots in [start_seq, end_seq]."""
        key = (start_seq, end_seq)
        if key in self.pending_gap_requests:
            return
        self.pending_gap_requests[key] = time.time()
        send(('MISSING_REQ', start_seq, end_seq, self), to=self.live_peers)

    def propose_gap_value(seq):
        """Leader proposes a value to fill a gap (reuse any accepted value, else NO-OP)."""
        # If we already have an accepted value for this seq, reuse it; otherwise NO-OP.
        existing = [e for e in self.accept_log if e[1] == seq]
        if existing:
            best = max(existing)
            val = best[2]
        else:
            val = 'NO-OP'
        self.accept_log.add((self.ballot_num, seq, val))
        if seq >= self.next_seq:
            self.next_seq = seq + 1
        send(('ACCEPT', self.ballot_num, seq, val), to=self.peers)
        send(('ACCEPTED', self.ballot_num, seq, val, self), to=self)

    def receive(msg=('MISSING_REQ', start_seq, end_seq, requester), from_=p):
        if self.is_failed:
            return
        entries = []
        for s in range(start_seq, end_seq + 1):
            if s in self.committed_log:
                entries.append((s, self.committed_log[s]))
            elif self.status == 'LEADER':
                # Proactively fill the gap so requester can progress
                propose_gap_value(s)
        if entries:
            send(('MISSING_RESP', entries), to=requester)

    def receive(msg=('MISSING_RESP', entries), from_=p):
        if self.is_failed:
            return
        updated = False
        for (seq, val) in entries:
            if seq not in self.committed_log:
                self.committed_log[seq] = val
                updated = True
                # Clear any pending requests covering this sequence
                self.pending_gap_requests = {rng: t for (rng, t) in self.pending_gap_requests.items() if not (rng[0] <= seq <= rng[1])}
        if updated:
            execute_committed()

    def receive(msg=('CATCHUP_REQUEST', last_exec, requester), from_=p):
        if self.is_failed:
            return
        missing = [(s, v) for (s, v) in self.committed_log.items() if s > last_exec]
        missing_sorted = sorted(missing, key=lambda e: e[0])
        send(('CATCHUP_RESPONSE', missing_sorted), to=requester)
    
    def receive(msg=('CATCHUP_RESPONSE', entries), from_=p):
        if self.is_failed:
            return
        for (seq, val) in entries:
            if seq <= self.last_executed_seq:
                continue
            # Store then try to execute in order
            self.committed_log[seq] = val
        execute_committed()

    def receive(msg=('INIT_CLIENTS', clients)):
        # Pre-seed known clients and default balances
        for c in clients:
            self.known_clients.add(c)
            if c not in self.db:
                self.db[c] = 10

    def receive(msg=('SET_LIVE', live_set)):
        # live_set is a set of node processes
        self.live_peers = set(live_set) - {self}
        self.live_cluster_size = len(live_set)
    
    def receive(msg=('RESET',)):
        output(f"{self.node_name} RESET. Peers: {len(self.peers)}")
        self.ballot_num = (1, self) if self.is_initial_leader else (0, self)
        self.status = 'LEADER' if self.is_initial_leader else 'FOLLOWER'
        self.leader = self if self.is_initial_leader else None
        self.accept_log = set()
        self.committed_log = {}
        self.promises = {}
        self.accepted_votes = {}
        self.next_seq = 1
        self.last_executed_seq = 0
        # self.db = {}  # Preserved for Project 1
        # self.known_clients = set() # Preserved for Project 1
        self.client_replies = {}
        self.is_failed = False
        self.new_view_messages = []
        self.last_leader_msg = time.time()
        self.buffered_prepare = None
        self.last_prepare_received_time = 0.0
    
    # === Print Functions ===
    
    def receive(msg=('PRINT_BALANCE', client_id)):
        balance = self.db.get(client_id, 10)
        output(f'{self.node_name}: {balance}')
    
    def receive(msg=('PRINT_DB',)):
        if self.is_failed:
            return
        # Print all known clients
        sorted_clients = sorted(list(self.known_clients))
        items = []
        for c in sorted_clients:
            items.append(f"{c}:{self.db.get(c, 10)}")
        output(f'{self.node_name} DB ({len(self.known_clients)}): {", ".join(items)}')
    
    def receive(msg=('PRINT_LOG',)):
        output(f'{self.node_name} Log: {sorted(self.accept_log)}')
    
    def receive(msg=('PRINT_STATUS', seq)):
        if seq in self.committed_log:
            if seq <= self.last_executed_seq:
                status = 'E'
            else:
                status = 'C'
        elif any(e[1] == seq for e in self.accept_log):
            status = 'A'
        else:
            status = 'X'
        output(f'{self.node_name}: {status}')
    
    def receive(msg=('PRINT_VIEW',)):
        for nv in self.new_view_messages:
            output(f'{self.node_name} View: {nv}')

# Main Function
def main():
    # Allow CSV selection via CLI: `demo` (default), `testcases`, or a custom path
    csv_arg = sys.argv[1] if len(sys.argv) > 1 else 'demo'
    csv_map = {
        'demo': 'CSE535-F25-Project-1-Demo-Tests.csv',
        'testcases': 'CSE535-F25-Project-1-Testcases.csv'
    }
    csv_file = csv_map.get(csv_arg.lower(), csv_arg)
    output(f"Using test file: {csv_file}")
    
    # Setup 5 nodes
    node_names = ['n1', 'n2', 'n3', 'n4', 'n5']
    nodes = new(Node, num=5)
    nodes_list = list(nodes)
    
    for i, node in enumerate(nodes_list):
        setup(node, (node_names[i], set(nodes_list), i == 0))
    
    start(nodes)
    
    # Map node names to processes
    node_map = {name: node for name, node in zip(node_names, nodes_list)}
    
    # Read CSV file
    test_sets = []
    all_clients = set()
    current_set = None
    
    with open(csv_file, 'r') as f:
        reader = csv.reader(f)
        next(reader)  # Skip header
        
        for row in reader:
            if not row or len(row) < 2:
                continue
            
            set_num, tx_str = row[0], row[1]
            live_nodes_str = row[2] if len(row) > 2 else ''
            
            if set_num and set_num.strip():
                if current_set:
                    test_sets.append(current_set)
                
                current_set = {
                    'id': set_num,
                    'transactions': [],
                    'live_nodes': parse_live_nodes(live_nodes_str) if live_nodes_str else []
                }
            
            if tx_str and tx_str.strip():
                if tx_str.strip().startswith('F('):
                    node_name = tx_str.strip()[2:-1]
                    current_set['transactions'].append(('FAIL', node_name))
                elif tx_str.strip().startswith('R('):
                    node_name = tx_str.strip()[2:-1]
                    current_set['transactions'].append(('RECOVER', node_name))
                else:
                    tx = parse_transaction(tx_str)
                    if tx:
                        # Skip LF when collecting clients
                        if tx == ('LF',):
                            current_set['transactions'].append(('TX', tx))
                            continue
                        current_set['transactions'].append(('TX', tx))
                        # Track client ids appearing in transactions
                        if len(tx) == 3:
                            all_clients.add(tx[0]); all_clients.add(tx[1])
                        elif len(tx) == 1:
                            all_clients.add(tx[0])
        
        if current_set:
            test_sets.append(current_set)
    
    # Create client
    client = new(Client, num=1)
    setup(client, (0, set(nodes_list), nodes_list[0]))
    start(client)

    # Create driver
    driver = new(Driver, num=1)
    setup(driver, (test_sets, node_names, node_map, set(nodes_list), client, all_clients))
    start(driver)

    # Keep main alive until driver finishes by waiting for DONE
    await(received(('DONE',)))
